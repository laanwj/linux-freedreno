/*
 * Copyright (C) 2013 Red Hat
 * Author: Rob Clark <robdclark@gmail.com>
 *
 * Copyright (c) 2014 The Linux Foundation. All rights reserved.
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 as published by
 * the Free Software Foundation.
 *
 * This program is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.
 *
 * You should have received a copy of the GNU General Public License along with
 * this program.  If not, see <http://www.gnu.org/licenses/>.
 */

#ifdef CONFIG_MSM_OCMEM
#  include <mach/ocmem.h>
#endif

#include "a2xx_gpu.h"

/* These are not in autogenerated headers */
#define A2XX_CP_INT_CNTL_SW_INT 		0x00080000L
#define A2XX_CP_INT_CNTL_T0_PACKET_IN_IB 	0x00800000L
#define A2XX_CP_INT_CNTL_OPCODE_ERROR 		0x01000000L
#define A2XX_CP_INT_CNTL_PROTECTED_MODE_ERROR 	0x02000000L
#define A2XX_CP_INT_CNTL_RESERVED_BIT_ERROR 	0x04000000L
#define A2XX_CP_INT_CNTL_IB_ERROR 		0x08000000L
#define A2XX_CP_INT_CNTL_IB2_INT 		0x20000000L
#define A2XX_CP_INT_CNTL_IB1_INT 		0x40000000L
#define A2XX_CP_INT_CNTL_RB_INT 		0x80000000L

#define A2XX_RBBM_INT_CNTL_RDERR_INT		0x00000001L
#define A2XX_RBBM_INT_CNTL_DISPLAY_UPDATE_INT	0x00000002L
#define A2XX_RBBM_INT_CNTL_GUI_IDLE_IN		0x00080000L

#define X_A2XX_CP_INT_MASK ( \
	A2XX_CP_INT_CNTL_SW_INT | \
	A2XX_CP_INT_CNTL_T0_PACKET_IN_IB | \
	A2XX_CP_INT_CNTL_OPCODE_ERROR | \
	A2XX_CP_INT_CNTL_PROTECTED_MODE_ERROR | \
	A2XX_CP_INT_CNTL_RESERVED_BIT_ERROR | \
	A2XX_CP_INT_CNTL_IB_ERROR | \
	A2XX_CP_INT_CNTL_IB2_INT | \
	A2XX_CP_INT_CNTL_IB1_INT | \
	A2XX_CP_INT_CNTL_RB_INT)

#define A2XX_CP_INT_MASK (A2XX_CP_INT_CNTL_RB_INT)

#define A2XX_RBBM_INT_MASK ( \
	A2XX_RBBM_INT_CNTL_RDERR_INT | \
	A2XX_RBBM_INT_CNTL_DISPLAY_UPDATE_INT )

extern bool hang_debug;

static void a2xx_dump(struct msm_gpu *gpu);

static uint32_t get_wptr(struct msm_ringbuffer *ring)
{
	return ring->cur - ring->start;
}

static void a2xx_me_init(struct msm_gpu *gpu)
{
	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
	struct msm_ringbuffer *ring = gpu->rb;
	int i;

	printk(KERN_INFO "@MF@ %s rptr=%d rb wptr=%d\n", __func__,
		adreno_gpu->memptrs->rptr, get_wptr(ring));

	/* From downstream freescale kernel driver (kgsl_ringbuffer_start()) */
	OUT_PKT3(ring, CP_ME_INIT, 18);
	OUT_RING(ring, 0x000003ff);	/* All fields present (bits 9:0) */
	OUT_RING(ring, 0x00000000);	/* Disable/Enable Real-Time Stream processing (present but ignored) */
	OUT_RING(ring, 0x00000000);	/* Enable (2D to 3D) and (3D to 2D) implicit synchronization (present but ignored) */

#define GSL_HAL_SUBBLOCK_OFFSET(reg)            ((unsigned int)((reg) - (0x2000)))
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_RB_SURFACE_INFO));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_PA_SC_WINDOW_OFFSET));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_VGT_MAX_VTX_INDX));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_SQ_PROGRAM_CNTL));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_RB_DEPTHCONTROL));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_PA_SU_POINT_SIZE));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_PA_SU_LINE_CNTL));
	OUT_RING(ring, GSL_HAL_SUBBLOCK_OFFSET(REG_A2XX_PA_SU_POLY_OFFSET_FRONT_SCALE));

	OUT_RING(ring, 0x80000180);	/* Vertex and Pixel Shader Start Addresses in instructions (3 DWORDS per instruction) */
	OUT_RING(ring, 0x00000001);	/* Maximum Contexts */
	OUT_RING(ring, 0x00000000);	/* Write Confirm Interval and The CP will wait the wait_interval * 16 clocks between polling */
	OUT_RING(ring, 0x00000000);	/* NQ and External Memory Swap */
	OUT_RING(ring, 0x00000000);	/* Protected mode error checking */
	OUT_RING(ring, 0x00000000);	/* Disable header dumping and Header dump address */
	OUT_RING(ring, 0x00000000);	/* Header dump size */

	printk(KERN_INFO "@MF@ preflush rptr=%d rb wptr=%d\n",
		adreno_gpu->memptrs->rptr, get_wptr(ring));

	gpu->funcs->flush(gpu);
	gpu->funcs->idle(gpu);
}

void mf_adreno_enable_regdump(int enable);

static int a2xx_hw_init(struct msm_gpu *gpu)
{
	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
	uint32_t *ptr, len;
	int i, ret;

	DBG("%s", gpu->name);

	//We need to make sure all blocks are powered up and clocked before
	//issuing a soft reset.  The overrides will be turned off (set to 0)
	//later in kgsl_yamato_start.
	gpu_write(gpu, REG_A2XX_RBBM_PM_OVERRIDE1, 0xfffffffe);
	gpu_write(gpu, REG_A2XX_RBBM_PM_OVERRIDE2, 0xffffffff);

	// soft reset
	gpu_write(gpu, REG_A2XX_RBBM_SOFT_RESET, 0xFFFFFFFF);
	msleep(50);
	gpu_write(gpu, REG_A2XX_RBBM_SOFT_RESET, 0x00000000);

	// RBBM control
	gpu_write(gpu, REG_A2XX_RBBM_CNTL, 0x00004442);

	// setup MH arbiter
    	gpu_write(gpu, REG_A2XX_MH_ARBITER_CONFIG, 0x07c8e590);

	// SQ_*_PROGRAM
	gpu_write(gpu, REG_A2XX_SQ_VS_PROGRAM, 0x00000000);
	gpu_write(gpu, REG_A2XX_SQ_PS_PROGRAM, 0x00000000);

	/* Freescale does this even when disabled in DT... */
	//gpu_write(gpu, REG_A2XX_MH_MMU_CONFIG, A2XX_MH_MMU_CONFIG_MMU_ENABLE);
	gpu_write(gpu, REG_A2XX_MH_MMU_CONFIG, 0);
	gpu_write(gpu, REG_A2XX_MH_MMU_MPU_BASE, 0x00000000);
	gpu_write(gpu, REG_A2XX_MH_MMU_MPU_END, 0xfffff000);

	//gpu_write(gpu, REG_A2XX_RB_EDRAM_INFO, adreno_gpu->gmem >> 14);
	gpu_write(gpu, REG_A2XX_RB_EDRAM_INFO, 4);
	gpu_write(gpu, REG_A2XX_RBBM_INT_CNTL, A2XX_RBBM_INT_MASK);

	ret = adreno_hw_init(gpu);
	if (ret)
		return ret;

	/* NOTE: PM4/micro-engine firmware registers look to be the same
	 * for a2xx and a2xx.. we could possibly push that part down to
	 * adreno_gpu base class.  Or push both PM4 and PFP but
	 * parameterize the pfp ucode addr/data registers..
	 */

	/* Load PM4: */
	ptr = (uint32_t *)(adreno_gpu->pm4->data);
	len = adreno_gpu->pm4->size / 4;
	DBG("loading PM4 ucode version: %x", ptr[1]);

	gpu_write(gpu, REG_AXXX_CP_DEBUG,
			AXXX_CP_DEBUG_MIU_128BIT_WRITE_ENABLE);
	gpu_write(gpu, REG_AXXX_CP_ME_RAM_WADDR, 0);
	for (i = 1; i < len; i++)
		gpu_write(gpu, REG_AXXX_CP_ME_RAM_DATA, ptr[i]);

	/* Load PFP: */
	ptr = (uint32_t *)(adreno_gpu->pfp->data);
	len = adreno_gpu->pfp->size / 4;
	DBG("loading PFP ucode version: %x", ptr[5]);

	gpu_write(gpu, REG_A2XX_CP_PFP_UCODE_ADDR, 0);
	for (i = 1; i < len; i++)
		gpu_write(gpu, REG_A2XX_CP_PFP_UCODE_DATA, ptr[i]);

	/* From 0x000c0804 magic in Freescale driver */
	gpu_write(gpu, REG_AXXX_CP_QUEUE_THRESHOLDS,
			AXXX_CP_QUEUE_THRESHOLDS_CSQ_IB1_START(4) |
			AXXX_CP_QUEUE_THRESHOLDS_CSQ_IB2_START(8) |
			AXXX_CP_QUEUE_THRESHOLDS_CSQ_ST_START(12));

	/* clear ME_HALT to start micro engine */
	gpu_write(gpu, REG_AXXX_CP_ME_CNTL, 0);

	mf_adreno_enable_regdump(0);
	a2xx_me_init(gpu);

	DBG("enable CP interrupts");

	gpu_write(gpu, REG_AXXX_CP_INT_CNTL, A2XX_CP_INT_MASK);

	return 0;
}

static void a2xx_recover(struct msm_gpu *gpu)
{
	/* dump registers before resetting gpu, if enabled: */
	if (hang_debug)
		a2xx_dump(gpu);
	gpu_write(gpu, REG_A2XX_RBBM_SOFT_RESET, 1);
	gpu_read(gpu, REG_A2XX_RBBM_SOFT_RESET);
	gpu_write(gpu, REG_A2XX_RBBM_SOFT_RESET, 0);
	adreno_recover(gpu);
}

static void a2xx_destroy(struct msm_gpu *gpu)
{
	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
	struct a2xx_gpu *a2xx_gpu = to_a2xx_gpu(adreno_gpu);

	DBG("%s", gpu->name);

	adreno_gpu_cleanup(adreno_gpu);

	kfree(a2xx_gpu);
}

static void a2xx_idle(struct msm_gpu *gpu)
{
	/* wait for ringbuffer to drain: */
	adreno_idle(gpu);

	/* then wait for GPU to finish: */
	if (spin_until(!(gpu_read(gpu, REG_A2XX_RBBM_STATUS) &
			A2XX_RBBM_STATUS_GUI_ACTIVE)))
		DRM_ERROR("%s: timeout waiting for GPU to idle!\n", gpu->name);

	/* TODO maybe we need to reset GPU here to recover from hang? */
}

static irqreturn_t a2xx_irq(struct msm_gpu *gpu)
{
	uint32_t status;
	uint32_t cp_status;

	status = gpu_read(gpu, REG_A2XX_RBBM_INT_STATUS);
	cp_status = gpu_read(gpu, REG_AXXX_CP_INT_STATUS);

	DBG("%s: %08x", gpu->name, status);

	printk(KERN_INFO "@MF@ %s status: rbbm=%08x cp=%08x\n", __func__,
		status, cp_status);
	// TODO

	gpu_write(gpu, REG_A2XX_RBBM_INT_ACK, status);
	gpu_write(gpu, REG_AXXX_CP_INT_ACK, cp_status);

	msm_gpu_retire(gpu);

	return IRQ_HANDLED;
}

static const unsigned int a2xx_registers[] = {
	/* Start, End pairs */
	REG_AXXX_CP_RB_BASE,		REG_AXXX_CP_RB_CNTL,
	REG_AXXX_CP_IB1_BASE,		REG_AXXX_CP_IB2_BUFSZ,
	REG_AXXX_CP_CSQ_IB1_STAT,	REG_AXXX_CP_CSQ_IB2_STAT,
	REG_AXXX_CP_INT_CNTL,		REG_AXXX_CP_INT_STATUS,

	REG_AXXX_CP_SCRATCH_REG0,	REG_AXXX_CP_SCRATCH_REG7,


/* TODO: just for debug
	0x0000, 0x0002, 0x0010, 0x0012, 0x0018, 0x0018, 0x0020, 0x0027,
	0x0029, 0x002b, 0x002e, 0x0033, 0x0040, 0x0042, 0x0050, 0x005c,
	0x0060, 0x006c, 0x0080, 0x0082, 0x0084, 0x0088, 0x0090, 0x00e5,
	0x00ea, 0x00ed, 0x0100, 0x0100, 0x0110, 0x0123, 0x01c0, 0x01c1,
	0x01c3, 0x01c5, 0x01c7, 0x01c7, 0x01d5, 0x01d9, 0x01dc, 0x01dd,
	0x01ea, 0x01ea, 0x01ee, 0x01f1, 0x01f5, 0x01f5, 0x01fc, 0x01ff,
	0x0440, 0x0440, 0x0443, 0x0443, 0x0445, 0x0445, 0x044d, 0x044f,
	0x0452, 0x0452, 0x0454, 0x046f, 0x047c, 0x047c, 0x047f, 0x047f,
	0x0578, 0x057f, 0x0600, 0x0602, 0x0605, 0x0607, 0x060a, 0x060e,
	0x0612, 0x0614, 0x0c01, 0x0c02, 0x0c06, 0x0c1d, 0x0c3d, 0x0c3f,
	0x0c48, 0x0c4b, 0x0c80, 0x0c80, 0x0c88, 0x0c8b, 0x0ca0, 0x0cb7,
	0x0cc0, 0x0cc1, 0x0cc6, 0x0cc7, 0x0ce4, 0x0ce5, 0x0e00, 0x0e05,
	0x0e0c, 0x0e0c, 0x0e22, 0x0e23, 0x0e41, 0x0e45, 0x0e64, 0x0e65,
	0x0e80, 0x0e82, 0x0e84, 0x0e89, 0x0ea0, 0x0ea1, 0x0ea4, 0x0ea7,
	0x0ec4, 0x0ecb, 0x0ee0, 0x0ee0, 0x0f00, 0x0f01, 0x0f03, 0x0f09,
	0x2040, 0x2040, 0x2044, 0x2044, 0x2048, 0x204d, 0x2068, 0x2069,
	0x206c, 0x206d, 0x2070, 0x2070, 0x2072, 0x2072, 0x2074, 0x2075,
	0x2079, 0x207a, 0x20c0, 0x20d3, 0x20e4, 0x20ef, 0x2100, 0x2109,
	0x210c, 0x210c, 0x210e, 0x210e, 0x2110, 0x2111, 0x2114, 0x2115,
	0x21e4, 0x21e4, 0x21ea, 0x21ea, 0x21ec, 0x21ed, 0x21f0, 0x21f0,
	0x2200, 0x2212, 0x2214, 0x2217, 0x221a, 0x221a, 0x2240, 0x227e,
	0x2280, 0x228b, 0x22c0, 0x22c0, 0x22c4, 0x22ce, 0x22d0, 0x22d8,
	0x22df, 0x22e6, 0x22e8, 0x22e9, 0x22ec, 0x22ec, 0x22f0, 0x22f7,
	0x22ff, 0x22ff, 0x2340, 0x2343, 0x2348, 0x2349, 0x2350, 0x2356,
	0x2360, 0x2360, 0x2440, 0x2440, 0x2444, 0x2444, 0x2448, 0x244d,
	0x2468, 0x2469, 0x246c, 0x246d, 0x2470, 0x2470, 0x2472, 0x2472,
	0x2474, 0x2475, 0x2479, 0x247a, 0x24c0, 0x24d3, 0x24e4, 0x24ef,
	0x2500, 0x2509, 0x250c, 0x250c, 0x250e, 0x250e, 0x2510, 0x2511,
	0x2514, 0x2515, 0x25e4, 0x25e4, 0x25ea, 0x25ea, 0x25ec, 0x25ed,
	0x25f0, 0x25f0, 0x2600, 0x2612, 0x2614, 0x2617, 0x261a, 0x261a,
	0x2640, 0x267e, 0x2680, 0x268b, 0x26c0, 0x26c0, 0x26c4, 0x26ce,
	0x26d0, 0x26d8, 0x26df, 0x26e6, 0x26e8, 0x26e9, 0x26ec, 0x26ec,
	0x26f0, 0x26f7, 0x26ff, 0x26ff, 0x2740, 0x2743, 0x2748, 0x2749,
	0x2750, 0x2756, 0x2760, 0x2760, 0x300c, 0x300e, 0x301c, 0x301d,
	0x302a, 0x302a, 0x302c, 0x302d, 0x3030, 0x3031, 0x3034, 0x3036,
	0x303c, 0x303c, 0x305e, 0x305f,
*/
	~0   /* sentinel */
};

#ifdef CONFIG_DEBUG_FS
static void a2xx_show(struct msm_gpu *gpu, struct seq_file *m)
{
	gpu->funcs->pm_resume(gpu);
	seq_printf(m, "status:   %08x\n",
			gpu_read(gpu, REG_A2XX_RBBM_STATUS));
	gpu->funcs->pm_suspend(gpu);
	adreno_show(gpu, m);
}
#endif

/* would be nice to not have to duplicate the _show() stuff with printk(): */
static void a2xx_dump(struct msm_gpu *gpu)
{
	printk("status:   %08x\n",
			gpu_read(gpu, REG_A2XX_RBBM_STATUS));
	adreno_dump(gpu);
}
/* Register offset defines for A2XX */
static const unsigned int a2xx_register_offsets[REG_ADRENO_REGISTER_MAX] = {
	REG_ADRENO_DEFINE(REG_ADRENO_CP_DEBUG, REG_AXXX_CP_DEBUG),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_ME_RAM_WADDR, REG_AXXX_CP_ME_RAM_WADDR),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_ME_RAM_DATA, REG_AXXX_CP_ME_RAM_DATA),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_PFP_UCODE_DATA,
			REG_A2XX_CP_PFP_UCODE_DATA),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_PFP_UCODE_ADDR,
			REG_A2XX_CP_PFP_UCODE_ADDR),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_RB_BASE, REG_AXXX_CP_RB_BASE),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_RB_RPTR_ADDR, REG_AXXX_CP_RB_RPTR_ADDR),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_RB_RPTR, REG_AXXX_CP_RB_RPTR),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_RB_WPTR, REG_AXXX_CP_RB_WPTR),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_ME_CNTL, REG_AXXX_CP_ME_CNTL),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_RB_CNTL, REG_AXXX_CP_RB_CNTL),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_IB1_BASE, REG_AXXX_CP_IB1_BASE),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_IB1_BUFSZ, REG_AXXX_CP_IB1_BUFSZ),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_IB2_BASE, REG_AXXX_CP_IB2_BASE),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_IB2_BUFSZ, REG_AXXX_CP_IB2_BUFSZ),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_TIMESTAMP, REG_AXXX_CP_SCRATCH_REG0),
	REG_ADRENO_DEFINE(REG_ADRENO_CP_ME_RAM_RADDR, REG_AXXX_CP_ME_RAM_RADDR),
	REG_ADRENO_DEFINE(REG_ADRENO_SCRATCH_ADDR, REG_AXXX_SCRATCH_ADDR),
	REG_ADRENO_DEFINE(REG_ADRENO_SCRATCH_UMSK, REG_AXXX_SCRATCH_UMSK),
};

static const struct adreno_gpu_funcs funcs = {
	.base = {
		.get_param = adreno_get_param,
		.hw_init = a2xx_hw_init,
		.pm_suspend = msm_gpu_pm_suspend,
		.pm_resume = msm_gpu_pm_resume,
		.recover = a2xx_recover,
		.last_fence = adreno_last_fence,
		.submit = adreno_submit,
		.flush = adreno_flush,
		.idle = a2xx_idle,
		.irq = a2xx_irq,
		.destroy = a2xx_destroy,
#ifdef CONFIG_DEBUG_FS
		.show = a2xx_show,
#endif
	},
};

static const struct msm_gpu_perfcntr perfcntrs[] = {
};

struct msm_gpu *a2xx_gpu_init(struct drm_device *dev)
{
	struct a2xx_gpu *a2xx_gpu = NULL;
	struct adreno_gpu *adreno_gpu;
	struct msm_gpu *gpu;
	struct msm_plat_private *priv = dev->dev_private;
	struct platform_device *pdev = priv->gpu_pdev;
	int ret;

	if (!pdev) {
		dev_err(dev->dev, "no a2xx device\n");
		ret = -ENXIO;
		goto fail;
	}

	a2xx_gpu = kzalloc(sizeof(*a2xx_gpu), GFP_KERNEL);
	if (!a2xx_gpu) {
		ret = -ENOMEM;
		goto fail;
	}

	adreno_gpu = &a2xx_gpu->base;
	gpu = &adreno_gpu->base;

	a2xx_gpu->pdev = pdev;

	gpu->perfcntrs = perfcntrs;
	gpu->num_perfcntrs = ARRAY_SIZE(perfcntrs);

	adreno_gpu->registers = a2xx_registers;
	adreno_gpu->reg_offsets = a2xx_register_offsets;

	ret = adreno_gpu_init(dev, pdev, adreno_gpu, &funcs);
	if (ret)
		goto fail;

	return gpu;

fail:
	if (a2xx_gpu)
		a2xx_destroy(&a2xx_gpu->base.base);

	return ERR_PTR(ret);
}
